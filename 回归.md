## 线性回归

### 回归模型

假定回归模型
$$
Y=b_{0}+b_{1} X+e
$$
$e$ 为随机误差
$$
E(e)=0\\
Var(e)=\sigma^2
$$

### 中心化

$$
Y_{i}=\beta_{0}+\beta_{1}\left(X_{i}-\bar{X}\right)+e_{i}, i=1, \cdots, n
$$

其中
$$
\beta_{1}=b_{1}, \beta_{0}=b_{0}+b_{1} \bar{X}
$$

### 参数估计

用 $\alpha_0$ 和 $\alpha_1$ 估计 $\beta$ 
$$
\hat{Y}_{i}=\alpha_{0}+\alpha_{1}\left(X_{i}-\bar{X}\right), i=1, \cdots, n
$$
损失函数
$$
Q\left(\alpha_{0}, \alpha_{1}\right)=\sum_{i=1}^{n}\left(Y_{i}-\hat{Y}_{i}\right)^{2}=\sum_{i=1}^{n}\left[Y_{i}-\alpha_{0}-\alpha_{1}\left(X_{i}-\bar{X}\right)\right]^{2}
$$
求
$$
\begin{aligned}
&\frac{\partial Q}{\partial \alpha_{0}}=-2 \sum_{i=1}^{n}\left(Y_{i}-\alpha_{0}-\alpha_{1}\left(X_{i}-\bar{X}\right)\right)=0\\
&\frac{\partial Q}{\partial \alpha_{1}}=-2 \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)\left[Y_{i}-\alpha_{0}-\alpha_{1}\left(X_{i}-\bar{X}\right)\right]=0
\end{aligned}
$$
注意到
$$
\sum_{i=1}^{n}\left(Y_{i}-\alpha_{0}-\alpha_{1}\left(X_{i}-\bar{X}\right)\right)=\sum_{i=1}^{n}Y_{i}-\alpha_{0}-\sum_{i=1}^{n}\alpha_{1}\left(X_{i}-\bar{X}\right)=\sum_{i=1}^{n}Y_{i}-\alpha_{0}
$$
所以
$$
a_0=\hat{\beta_0}=\bar{Y}=\frac{1}{n} \sum_{i=1}^{n}\left(\beta_{0}+\beta_{1}\left(X_{i}-\bar{X}\right)+e_{i}\right)=\beta_0+\bar{e}
$$
代入下方
$$
\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)\left[Y_{i}-\bar{Y}\right]=\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)\alpha_{1}\left(X_{i}-\bar{X}\right)
$$
所以
$$
a_1=\hat{\beta_1}=\frac{\sum _ { i = 1 } ^ { n } \left( X _ { i } - \bar { X } \right) Y _ { i } }{ \sum _ { i = 1 } ^ { n } \left( X _ { i } - \bar { X } \right) ^ { 2 }}=\frac{\sum _ { i = 1 } ^ { n } \left( X _ { i } - \bar { X } \right) e _ { i } }{ \sum _ { i = 1 } ^ { n } \left( X _ { i } - \bar { X } \right) ^ { 2 }}+\beta_1
$$

#### 估计的性质

这个估计是无偏的
$$
E(\hat{\beta_0})=\beta_0+E(\bar{e})= \beta _ { 0 } 
$$

$$
E(\hat{\beta_1})=\frac{\sum _ { i = 1 } ^ { n } \left( X _ { i } - \bar { X } \right)E( Y _ { i } )}{ \sum _ { i = 1 } ^ { n } \left( X _ { i } - \bar { X } \right) ^ { 2 }}=\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)\left[\beta_{0}+\beta_{1}\left(X_{i}-\bar{X}\right)\right] / \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}=\beta_1
$$

方差为
$$
Var(\hat{\beta_1})=\frac{\sigma^2}{n}
$$

$$
Var({\beta_1})=\frac{\sum _ { i = 1 } ^ { n } \left( X _ { i } - \bar { X } \right)^2Var( Y _ { i }) }{\left[ \sum _ { i = 1 } ^ { n } \left( X _ { i } - \bar { X } \right) ^ { 2 }\right]^2}=\frac{\sigma^2}{\sum _ { i = 1 } ^ { n } \left( X _ { i } - \bar { X } \right)^2}
$$

且两者不相关:
$$
E(\hat{\beta_0}\hat{\beta_1})=E(\frac{\sum _ { i = 1 } ^ { n } \left( X _ { i } - \bar { X } \right) Y _ { i }\bar{Y} }{ \sum _ { i = 1 } ^ { n } \left( X _ { i } - \bar { X } \right) ^ { 2 }})
$$

$$
E(\sum _ { i = 1 } ^ { n }   Y _ { i }\bar{Y} )=E[(\beta_0+\beta_1(X_i-\bar{X})+e)\bar{Y}]\\=\beta_0E(\hat{Y})+\beta_1(X_i-\bar{X})E(\hat{Y})+E(e\hat{Y})=\beta_0E(\hat{Y})+\beta_1(X_i-\bar{X})E(\hat{Y})
$$

所以
$$
E(\hat{\beta_0}\hat{\beta_1})=\frac{\sum _ { i = 1 } ^ { n } \left( X _ { i } - \bar { X } \right) [\beta_0E(\hat{Y})+\beta_1(X_i-\bar{X})E(\hat{Y})] }{ \sum _ { i = 1 } ^ { n } \left( X _ { i } - \bar { X } \right) ^ { 2 }}=\beta_1E(\hat{Y})=\beta_0\beta_1
$$

### 残差

预测与观测之差为残差:
$$
\delta_{i}=Y_{i}-\hat{Y}_{i}, i=1, \cdots, n
$$
残差可以用于估计 $\sigma^2$:
$$
\delta_i=Y_{i}-\hat{Y}_{i}=\beta_{0}-\hat{\beta}_{0}+(\beta_{1}-\hat{\beta_{1}})\left(X_{i}-\bar{X}\right)+e_{i}
$$
其中
$$
\beta_{0}-\hat{\beta}_{0}=-\bar{e}
$$

$$
\beta_{1}-\hat{\beta_{1}}=-\frac{\sum _ { j = 1 } ^ { n } \left( X _ { j } - \bar { X } \right) e _ { j } }{ \sum _ { j = 1 } ^ { n } \left( X _ { j } - \bar { X } \right) ^ { 2 }}
$$

所以
$$
\delta_i=e_i-\bar{e}-(X_i-\bar{X})
\frac{\sum _ { j = 1 } ^ { n } \left( X _ { j } - \bar { X } \right) e _ { j } }{ \sum _ { j = 1 } ^ { n } \left( X _ { j } - \bar { X } \right) ^ { 2 }}
$$
注意到
$$
\sum_{i=1}^{n}\left[(X_i-\bar{X})\frac{\sum _ { j = 1 } ^ { n } \left( X _ { j } - \bar { X } \right) e _ { j } }{ \sum _ { j = 1 } ^ { n } \left( X _ { j } - \bar { X } \right) ^ { 2 }}\right]^2
=\frac{\left[\sum _ { j = 1 } ^ { n } \left( X _ { j } - \bar { X } \right)e_j \right]^2\sum_{i=1}^{n}(X_i-\bar{X})^2}{\left[ \sum _ { j = 1 } ^ { n } \left( X _ { j } - \bar { X } \right) ^ { 2 }\right]^2}
=\frac{\left[\sum _ { j = 1 } ^ { n } \left( X _ { j } - \bar { X } \right)e_j \right]^2}{ \sum _ { j = 1 } ^ { n } \left( X _ { j } - \bar { X } \right) ^ { 2 }}
$$
且
$$
\sum_{i=1}^{n}\left(e_{i}-\bar{e}\right)\left(X_{i}-\bar{X}\right)=\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right) e_{i}
$$
所以
$$
\sum_{i=1}^{n}\left(e_{i}-\bar{e}\right)\left(X_{i}-\bar{X}\right)\frac{\sum _ { j = 1 } ^ { n } \left( X _ { j } - \bar { X } \right) e _ { j } }{ \sum _ { j = 1 } ^ { n } \left( X _ { j } - \bar { X } \right) ^ { 2 }}
=\frac{\left[\sum _ { j = 1 } ^ { n } \left( X _ { j } - \bar { X } \right)e_j \right]^2}{ \sum _ { j = 1 } ^ { n } \left( X _ { j } - \bar { X } \right) ^ { 2 }}
$$
所以
$$
\sum_{i=1}^{n} \delta_{i}^{2}=

\sum_{i=1}^{n}\left(e_{i}-\bar{e}\right)^{2}

-\frac{\left[\sum _ { j = 1 } ^ { n } \left( X _ { j } - \bar { X } \right)e_j \right]^2}{ \sum _ { j = 1 } ^ { n } \left( X _ { j } - \bar { X } \right) ^ { 2 }}
$$
注意到
$$
E(\sum_{i=1}^{n}\left(e_{i}-\bar{e}\right)^{2})=(n-1)\sigma^2
$$

$$
E\left\{\left[\sum _ { j = 1 } ^ { n } \left( X _ { j } - \bar { X } \right)e_j \right]^2\right\}=Var(\sum _ { j = 1 } ^ { n } \left( X _ { j } - \bar { X } \right)e_j)=\sigma^{2} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}
$$

所以
$$
E\left(\sum_{i=1}^{n} \delta_{i}^{2}\right)=(n-2) \sigma^{2}
$$
